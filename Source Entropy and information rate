// Caption: Entropy, Information Rate
// Example 9.16, page no. 404

clear;
clc;

// Probability symbols
px1 = 1/2;
px2 = 1/4;
px3 = 1/8;
px4 = 1/16;
px5 = 1/16;
Tb = 10^-3;

// Source entropy H(X)
HX = px1*log2(1/px1) + px2*log2(1/px2) + px3*log2(1/px3) + px4*log2(1/px4) + px5*log2(1/px5);

// Display entropy
mprintf("i) source entropy\n\n\tH(X) = %.2f bits/symbol\n", HX);

// Information rate
r = 1/Tb;
R = r * HX;

// Display information rate
mprintf("\n\nii) information rate\n\n\tR = %.0f bits/sec\n", R);
